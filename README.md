# ğŸ§ª ETL Pipeline using Pandas and Scikit-learn

This repository contains a simple ETL (Extract, Transform, Load) pipeline implemented using Python, Pandas, and Scikit-learn.

---

## ğŸ“ Files Included

- `data.csv` â€” Sample raw dataset containing missing values and numeric/categorical columns.
- `etl_pipeline.py` â€” A Python script to run the ETL pipeline.
- `etl_pipeline_notebook.ipynb` â€” A Jupyter Notebook version of the same ETL process.
- `cleaned_data.csv` â€” Output file after running the ETL process (created after execution).

---

## ğŸš€ What This Project Does

This project:
- Extracts data from a CSV file
- Transforms the data by:
  - Dropping missing values
  - Scaling numeric features using `StandardScaler`
- Loads (saves) the cleaned data to a new CSV file

---

## ğŸ”§ Requirements

- Python 3.x
- Pandas
- Scikit-learn

Install them using:

```bash
pip install pandas scikit-learn

ğŸ“Œ How to Run
Option 1: Run the Python Script
bash
Copy
Edit
python etl_pipeline.py
ğŸ““ Option 2: Use the Jupyter Notebook
Open etl_pipeline_notebook.ipynb in Jupyter

Run all cells

The cleaned data will be saved as cleaned_data.csv

ğŸ’¡ Example Output
Original Data:

id	age	salary	department
1	25	50000	HR
2	30	60000	IT
â€¦	â€¦	â€¦	â€¦

Transformed Data (after scaling & cleaning):

id	age	salary
â€¦	â€¦	â€¦

ğŸ“‚ Use Case
This project demonstrates a basic data engineering workflow. It is ideal for:

Beginners learning about ETL

Preprocessing before machine learning

Data cleaning steps in data science pipelines










