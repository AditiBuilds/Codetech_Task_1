{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf973da3",
   "metadata": {},
   "source": [
    "# üß™ ETL Pipeline using Pandas & Scikit-learn\n",
    "This notebook demonstrates a basic ETL (Extract, Transform, Load) process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2818c2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d09ee2",
   "metadata": {},
   "source": [
    "## üîç Step 1: Extract\n",
    "Load the sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c54234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "print(\"Original Data:\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6972b294",
   "metadata": {},
   "source": [
    "## üîß Step 2: Transform\n",
    "Drop missing values and scale numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294887c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "df_clean = df.dropna()\n",
    "\n",
    "# Scale numeric columns\n",
    "scaler = StandardScaler()\n",
    "numeric_cols = df_clean.select_dtypes(include='number').columns\n",
    "df_clean[numeric_cols] = scaler.fit_transform(df_clean[numeric_cols])\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4df367",
   "metadata": {},
   "source": [
    "## üíæ Step 3: Load\n",
    "Save the cleaned and transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e0744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('cleaned_data.csv', index=False)\n",
    "print(\"ETL process complete. Cleaned data saved to cleaned_data.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}